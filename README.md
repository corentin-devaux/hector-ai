Hector AI Agent
<div align="center">
<img src="https://img.shields.io/badge/Hector%20AI-v1.0-blue?style=for-the-badge&logo=appveyor" alt="Version"/>
<img src="https://img.shields.io/badge/Python-3.10+-yellow.svg?style=for-the-badge&logo=python" alt="Python"/>
<img src="https://img.shields.io/badge/PyTorch-GPU%20Ready-orange?style=for-the-badge&logo=pytorch" alt="PyTorch"/>
</div>
<div align="center">
<img src="https://img.shields.io/badge/FastAPI-Backend-green?style=for-the-badge&logo=fastapi" alt="FastAPI"/>
<img src="https://img.shields.io/badge/PyQt6-Frontend-purple?style=for-the-badge&logo=qt" alt="PyQt6"/>
</div>
<p align="center">
<em>Un assistant IA multimodal capable d'interagir par la voix, de naviguer sur le web et de g√©n√©rer du contenu, le tout propuls√© par une architecture client-serveur performante.</em>
</p>
üöÄ Fonctionnalit√©s
üó£Ô∏è Interaction Vocale Naturelle : Parlez √† Hector et √©coutez ses r√©ponses gr√¢ce √† une reconnaissance vocale (Whisper) et une synth√®se vocale (gTTS) de haute qualit√©.
üß† Raisonnement Avanc√© : Propuls√© par un grand mod√®le de langage (Gemma) pour comprendre, planifier et ex√©cuter des t√¢ches complexes.
üåê Navigation Web Autonome : Hector peut ouvrir un navigateur, analyser le contenu des pages, cliquer sur des √©l√©ments et remplir des formulaires pour atteindre ses objectifs.
üé¨ G√©n√©ration de Contenu Vid√©o : Cr√©ez des vid√©os uniques √† partir d'une simple description textuelle gr√¢ce au mod√®le Wan-2.2.
üíª Architecture Client-Serveur Robuste : L'interface utilisateur (client) reste l√©g√®re sur votre PC, tandis que les calculs IA intensifs sont d√©port√©s sur un serveur GPU puissant pour une performance maximale.
üèõÔ∏è Architecture du Projet
Le projet est con√ßu pour s√©parer l'interface de l'intelligence. Les deux composants communiquent via une API REST rapide construite avec FastAPI.
Composant	Description	Ex√©cution
ü§ñ Serveur API	Le "cerveau" et les "muscles". Charge et ex√©cute les mod√®les d'IA (LLM, Vid√©o) sur le GPU.	Machine distante (ex: RunPod, AWS) avec GPU
üñ•Ô∏è Client GUI	Le "visage" et les "sens". G√®re l'interface graphique, le micro, les haut-parleurs et le navigateur web.	PC de l'utilisateur (Windows, macOS, Linux)
üõ†Ô∏è Pr√©requis
Pour le Serveur (GPU)
Un serveur Linux (Ubuntu 22.04 recommand√©) avec un GPU NVIDIA et les drivers CUDA.
Python 3.10+
Git et Git LFS
Pour le Client (Local)
Un ordinateur Windows, macOS ou Linux.
Python 3.10+
Git
Un microphone et des haut-parleurs fonctionnels.
‚öôÔ∏è Guide d'Installation
1. Configuration du Serveur (Machine GPU distante)
Connectez-vous √† votre serveur via SSH et suivez ces √©tapes.
a. Cloner le d√©p√¥t et naviguer dans le dossier :
code
Bash
git clone https://github.com/corentin-devaux/hector-ai-agent.git
cd hector-ai-agent
b. Installer les d√©pendances :
code
Bash
# Il est fortement recommand√© d'utiliser un environnement virtuel
python3 -m venv .venv
source .venv/bin/activate

# Mettre √† jour pip et installer les paquets
pip install --upgrade pip
pip install -r requirements.txt
‚ö†Ô∏è Note Cruciale sur la Performance GPU : Pour que le LLM utilise le GPU, llama-cpp-python doit √™tre compil√© avec le support CUDA. Si vous constatez que seul le CPU est utilis√©, forcez la r√©installation :
code
Bash
pip uninstall -y llama-cpp-python
CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install --no-cache-dir llama-cpp-python
c. T√©l√©charger les mod√®les d'IA :
code
Bash
# Cr√©ez le dossier des mod√®les
mkdir -p models
cd models

# 1. T√©l√©chargez le mod√®le LLM (Gemma)
# Assurez-vous que le nom du fichier de sortie (-O) correspond √† `MODEL_FILE` dans src/config.py
wget "URL_DU_MODELE_GEMMA_GGUF" -O gemma-model.gguf

# 2. T√©l√©chargez le mod√®le de g√©n√©ration vid√©o (Wan-2.2)
# Wan-2.2 est souvent distribu√© sous forme de d√©p√¥t complet
git clone URL_DU_MODELE_WAN2.2 wan-2.2-model

# ... Ajoutez ici les commandes pour les autres mod√®les si n√©cessaire ...
V√©rifiez que les chemins dans src/config.py pointent vers les bons noms de fichiers/dossiers.
2. Configuration du Client (Votre PC local)
a. Cloner le d√©p√¥t :
code
Bash
git clone https://github.com/corentin-devaux/hector-ai-agent.git
cd hector-ai-agent
b. Cr√©er un environnement virtuel et installer les d√©pendances :
code
Bash
# Cr√©ez l'environnement virtuel
python -m venv .venv

# Activez-le (adaptez la commande √† votre OS)
# Windows: .\.venv\Scripts\activate
# macOS/Linux: source .venv/bin/activate

# Installez les paquets
pip install -r requirements.txt
c. Configurer l'adresse du serveur :
Ouvrez le fichier src/gui/main_window.py et modifiez la variable SERVER_URL avec l'adresse IP et le port public de votre serveur :
code
Python
# Exemple
self.SERVER_URL = "http://123.45.67.89:12345"
‚ñ∂Ô∏è Lancement
L'application se lance en deux temps : d'abord le serveur, puis le client.
√âtape 1 : D√©marrer le Serveur
Sur votre machine GPU distante, depuis la racine du projet :
code
Bash
# Activez l'environnement virtuel si ce n'est pas d√©j√† fait
source .venv/bin/activate

# Lancez l'API
python src/server_api.py
Le serveur chargera les mod√®les et se mettra en √©coute.
√âtape 2 : Lancer le Client
Sur votre PC local, depuis la racine du projet :
code
Bash
# Activez votre environnement virtuel local
# .\.venv\Scripts\activate

# Lancez l'interface graphique
python src/gui/main_window.py
L'interface d'Hector appara√Æt. Vous √™tes pr√™t √† interagir !
üß† Mod√®les d'IA Utilis√©s
Composant	Mod√®le	R√¥le
Cerveau (LLM)	Gemma 9B GGUF	Raisonnement, planification, g√©n√©ration
Oreilles (STT)	OpenAI Whisper (large-v3)	Transcription de la parole en texte
Vid√©o (Gen)	Wan-2.2 (Mod√®le de diffusion texte-vers-vid√©o)	Cr√©ation de vid√©os √† partir de prompts
Voix (TTS)	Google Text-to-Speech (gTTS)	Synth√®se vocale
Tous les mod√®les sont configurables dans src/config.py.
ü§ù Contribuer
Les contributions sont les bienvenues ! Pour toute suggestion ou am√©lioration, veuillez ouvrir une issue ou soumettre une pull request.
üìÑ Licence
Ce projet est distribu√© sous la Licence MIT. Voir le fichier LICENSE pour plus de d√©tails.
